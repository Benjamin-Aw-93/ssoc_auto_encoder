{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be937d8-e201-4ea6-a4be-2ead9cb156bf",
   "metadata": {},
   "source": [
    "## XGBoost Test\n",
    "\n",
    "**Author:** Shaun Khoo  \n",
    "**Date:** 14 Oct 2021  \n",
    "**Context:** Need a suitable benchmark to compare our hierarchical classifier against (and not just to another neural network)  \n",
    "**Objective:** Compare how much better a hierarchical multi-class classification model is compared to a flat multi-class classification model. We use XGBoost as the primary algorithm as this is sufficiently performant and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79a0cd-3522-47e2-be13-f62c409767d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setting up\n",
    "\n",
    "We import the required libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d899b576-b143-44c4-890f-f86eb7f6650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d5e804-33a4-4b2a-8bcb-4377b79d68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "312a6528-160b-4857-9c0c-3e54baa4e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Processed/Training/train_full.csv')\n",
    "SSOC_2020 = pd.read_csv('Data/Processed/Training/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b427137-0363-464a-b351-dbd5a2fffd35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generating embeddings for the train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca7239c6-6430-4f49-88ec-22850c9dc631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a9927c9-8791-48ae-b7b1-f0dc64dbcaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42842"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e779626a-75d5-452d-9324-8aa82809b4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 42900/42842... took 0.20 mins\r"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "import time\n",
    "for i in range(len(data)):\n",
    "    if i % 100 == 0:\n",
    "        start = time.time()\n",
    "        \n",
    "        sentences = data['Cleaned_Description'][i:min(i+100, len(data))].tolist()\n",
    "\n",
    "        encoded_input = tokenizer(text = sentences, \n",
    "                                  max_length = 512,\n",
    "                                  add_special_tokens = True,\n",
    "                                  padding = 'max_length', \n",
    "                                  truncation = True,\n",
    "                                  return_tensors = 'pt')\n",
    "\n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "        # Perform pooling. In this case, max pooling.\n",
    "        sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "        all_embeddings.append(sentence_embeddings)\n",
    "        \n",
    "        print(f'Processed {i+100}/{len(data)}... took {(time.time()-start)/60:.2f} mins\\r', end = \"\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a725d1c-3fc5-454a-83f0-63dd65790a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 768])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings[428].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a59ab6-8bb1-477e-ac77-f643e552a5af",
   "metadata": {},
   "source": [
    "Adding in extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e16f791e-719a-41c4-9c62-c231b173c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = pd.read_csv('Data/Processed/Training/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a56efa1a-1018-48fe-b096-f7a76bccb59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/997... took 0.47 mins\r"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "import time\n",
    "\n",
    "extra_embeddings = []\n",
    "\n",
    "for i in range(len(extra_data)):\n",
    "    if i % 100 == 0:\n",
    "        start = time.time()\n",
    "        \n",
    "        sentences = extra_data['Description'][i:min(i+100, len(extra_data))].tolist()\n",
    "\n",
    "        encoded_input = tokenizer(text = sentences, \n",
    "                                  max_length = 512,\n",
    "                                  add_special_tokens = True,\n",
    "                                  padding = 'max_length', \n",
    "                                  truncation = True,\n",
    "                                  return_tensors = 'pt')\n",
    "\n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "        # Perform pooling. In this case, max pooling.\n",
    "        sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "        extra_embeddings.append(sentence_embeddings)\n",
    "        \n",
    "        print(f'Processed {min(i+100, len(extra_data))}/{len(extra_data)}... took {(time.time()-start)/60:.2f} mins\\r', end = \"\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e6ea727d-bd65-4d9e-af9f-7c3fc6366bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings.extend(extra_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "76d164cb-c8f0-4898-b13f-fdf45de04635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "output = np.concatenate(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3ce89664-5ea8-4902-afe4-56ff8dbaa3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43839, 768)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5ca23c75-7e4d-4bd9-89d1-2a79f7df06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1f878167-a061-4940-a1e6-113d11fd84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings.to_csv('Data/Processed/Training/Sentence_Embeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb473b67-2eed-4fa4-94ae-c1e5fbb8d487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Splitting into train/test sets\n",
    "\n",
    "We need to be careful with the train/test split to ensure that the test set only includes SSOCs that were already in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8bdcd28c-aa58-4f11-84a8-923a14543ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data['Cleaned_Description'] = extra_data['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "62041f77-a16a-410c-95d4-40e1f8e48e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "old_data = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b9d45e85-d51f-4287-8f77-eec33cde417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, extra_data], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d0a82b-7503-4b4b-bb80-1d5089c45dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8568.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1581d2d5-c67c-4f6f-a6b7-a100d4af3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = data[data.duplicated('SSOC 2020')].sample(8568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2234b05f-9246-4ef3-8055-9353ef3434e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data.filter(items = [idx for idx in data.index if idx not in test_set.index],\n",
    "                        axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c4ff60d5-d7a1-4345-8b15-c8b4f18078f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv('Data/Processed/Training/train-7oct.csv')\n",
    "test_set.to_csv('Data/Processed/Training/test-7oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a481d910-eaf0-4832-bcfa-9a4a93e7d561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35271, 768)\n",
      "(35271,)\n",
      "(8568, 768)\n",
      "(8568,)\n"
     ]
    }
   ],
   "source": [
    "X_train = sentence_embeddings.loc[train_set.index].reset_index(drop = True)\n",
    "y_train = train_set['SSOC 2020']\n",
    "X_test = sentence_embeddings.loc[test_set.index].reset_index(drop = True)\n",
    "y_test = test_set['SSOC 2020']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad27c84-c0ba-4f58-ba1f-987028c666c1",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "Import the encoding of SSOC to index for each digit-level of SSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24019b6e-2fe2-4844-9a11-442712708be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"encoding.json\", 'r') as outfile:\n",
    "    encoding = json.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be142046-0f0e-4b7a-943c-b5e0f59226f7",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8ce877b-ef2f-46e4-9de4-fb71f52601c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "67b89018-7d6a-4d37-95d9-3cb018957b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 300,\n",
    "    'objective': 'multi:softprob',\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'max_depth': 10,\n",
    "    'min_child_weight': 10,\n",
    "    'gamma': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a8ed8-fff7-4580-b895-d202ae9d75bb",
   "metadata": {},
   "source": [
    "**Layer 1**: 1-Digit SSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a12cbf3e-f601-4b5b-9ef3-d5b6454314be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1D = y_train.astype('str').str.slice(0, 1).map(encoding['SSOC_1D']['ssoc_idx']).tolist()\n",
    "y_test_1D = y_test.astype('str').str.slice(0, 1).map(encoding['SSOC_1D']['ssoc_idx']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a896b13f-664f-4e84-acac-cb9042816b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=5, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=10, min_child_weight=10, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='gpu_hist', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_1D = XGBClassifier(**xgb_params)\n",
    "xgb_1D.fit(X_train, y_train_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "79a4ef64-7b81-4b2e-a174-8ac96cdd4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6da69b36-2e9a-4bbd-99e9-2c8e8efd5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      6327\n",
      "           1       0.95      0.90      0.92     13754\n",
      "           2       0.80      0.83      0.82      7387\n",
      "           3       0.83      0.87      0.85      3117\n",
      "           4       0.86      0.92      0.89      1624\n",
      "           5       0.68      1.00      0.81        13\n",
      "           6       0.74      0.96      0.84       698\n",
      "           7       0.91      0.92      0.92      1402\n",
      "           8       0.88      0.89      0.88       949\n",
      "\n",
      "    accuracy                           0.88     35271\n",
      "   macro avg       0.83      0.90      0.86     35271\n",
      "weighted avg       0.88      0.88      0.88     35271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(xgb_1D.predict(X_train), y_train_1D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "545d35a2-5845-4532-8432-71be14132426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      1525\n",
      "           1       0.81      0.74      0.77      3403\n",
      "           2       0.51      0.50      0.51      1945\n",
      "           3       0.55      0.61      0.58       740\n",
      "           4       0.58      0.63      0.61       372\n",
      "           6       0.33      0.65      0.44       100\n",
      "           7       0.73      0.76      0.74       311\n",
      "           8       0.50      0.61      0.55       172\n",
      "\n",
      "    accuracy                           0.65      8568\n",
      "   macro avg       0.58      0.64      0.60      8568\n",
      "weighted avg       0.66      0.65      0.65      8568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(xgb_1D.predict(X_test), y_test_1D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52809edf-f956-4056-afba-0cc7332c4d4c",
   "metadata": {},
   "source": [
    "**Layer 2**: 2-Digit SSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "63680593-4e2c-44d8-b2d3-fc6185ea9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_1D_train = pd.DataFrame(xgb_1D.predict_proba(X_train))\n",
    "pred_proba_1D_train.columns = [f'pred_proba_1D_{col}' for col in pred_proba_1D_train.columns]\n",
    "pred_proba_1D_test = pd.DataFrame(xgb_1D.predict_proba(X_test))\n",
    "pred_proba_1D_test.columns = [f'pred_proba_1D_{col}' for col in pred_proba_1D_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "451ff914-f631-4e57-bd3a-ff5591a1aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35271, 9)\n",
      "(8568, 9)\n"
     ]
    }
   ],
   "source": [
    "print(pred_proba_1D_train.shape)\n",
    "print(pred_proba_1D_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7712f409-58a1-4a24-92cb-d5faa4ac2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_2D = y_train.astype('str').str.slice(0, 2).map(encoding['SSOC_2D']['ssoc_idx']).tolist()\n",
    "y_test_2D = y_test.astype('str').str.slice(0, 2).map(encoding['SSOC_2D']['ssoc_idx']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "27ab67ac-d798-4dff-a42a-be5b1b6ecca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2D = pd.concat([X_train, pred_proba_1D_train], axis = 1)\n",
    "X_test_2D = pd.concat([X_test, pred_proba_1D_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1b89c1d0-3b6c-4df7-abf3-465dbc44e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
       "              gamma=5, gpu_id=0, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=10, min_child_weight=10, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=300, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='gpu_hist', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_2D = XGBClassifier(**xgb_params)\n",
    "xgb_2D.fit(X_train_2D, y_train_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "15a26a15-6c75-4daf-bece-cffaf8c4ea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.86      0.73       482\n",
      "           1       0.90      0.84      0.87      2585\n",
      "           2       0.85      0.85      0.85      2218\n",
      "           3       0.84      0.88      0.86       990\n",
      "           4       0.92      0.89      0.91      6070\n",
      "           5       0.93      0.96      0.95       449\n",
      "           6       0.91      0.93      0.92       251\n",
      "           7       0.82      0.86      0.84      2396\n",
      "           8       0.90      0.87      0.89      3756\n",
      "           9       0.85      0.94      0.89       296\n",
      "          10       0.89      0.89      0.89      1673\n",
      "          11       0.83      0.94      0.88       297\n",
      "          12       0.92      0.88      0.90      4832\n",
      "          13       0.76      0.96      0.85       274\n",
      "          14       0.60      1.00      0.75        55\n",
      "          15       0.94      0.95      0.94       526\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.88      0.88      0.88      1330\n",
      "          19       0.85      0.91      0.88       565\n",
      "          20       0.89      0.91      0.90      1305\n",
      "          21       0.21      1.00      0.35         3\n",
      "          22       0.94      0.91      0.93      1014\n",
      "          23       0.83      0.90      0.86       385\n",
      "          24       0.88      0.96      0.92       132\n",
      "          25       0.94      0.98      0.96       169\n",
      "          26       0.13      1.00      0.24         2\n",
      "          27       0.67      0.77      0.71        13\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.92      0.89      0.90       450\n",
      "          30       0.75      0.95      0.84        38\n",
      "          31       0.60      0.95      0.73        19\n",
      "          32       0.76      0.96      0.85        46\n",
      "          33       0.79      0.85      0.82       313\n",
      "          34       0.75      0.94      0.84       132\n",
      "          35       0.20      1.00      0.33         2\n",
      "          36       0.98      0.95      0.96      1268\n",
      "          37       0.89      0.87      0.88       215\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.79      0.88      0.83       120\n",
      "          40       0.95      0.93      0.94       547\n",
      "          41       0.72      0.96      0.82        53\n",
      "\n",
      "    accuracy                           0.89     35271\n",
      "   macro avg       0.71      0.83      0.74     35271\n",
      "weighted avg       0.89      0.89      0.89     35271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(xgb_2D.predict(X_train_2D), y_train_2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e56d5cd5-fdaa-4ec4-8868-56a3b5b3124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.29      0.24       119\n",
      "           1       0.50      0.47      0.49       662\n",
      "           2       0.32      0.33      0.32       507\n",
      "           3       0.45      0.44      0.44       254\n",
      "           4       0.63      0.58      0.60      1531\n",
      "           5       0.68      0.81      0.74        95\n",
      "           6       0.43      0.55      0.48        42\n",
      "           7       0.37      0.34      0.35       621\n",
      "           8       0.72      0.70      0.71       943\n",
      "           9       0.31      0.50      0.38        40\n",
      "          10       0.39      0.43      0.41       359\n",
      "          11       0.32      0.44      0.37        57\n",
      "          12       0.46      0.41      0.43      1400\n",
      "          13       0.19      0.42      0.26        31\n",
      "          14       0.14      0.67      0.24         3\n",
      "          15       0.77      0.74      0.75       126\n",
      "          18       0.44      0.48      0.46       327\n",
      "          19       0.29      0.33      0.31       103\n",
      "          20       0.46      0.47      0.47       335\n",
      "          22       0.64      0.62      0.63       242\n",
      "          23       0.25      0.30      0.28        86\n",
      "          24       0.33      0.53      0.41        15\n",
      "          25       0.70      0.91      0.79        35\n",
      "          26       0.00      0.00      0.00         0\n",
      "          29       0.43      0.52      0.47        77\n",
      "          30       0.33      0.40      0.36         5\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.12      0.33      0.18         3\n",
      "          33       0.24      0.35      0.29        60\n",
      "          34       0.04      0.08      0.06        12\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.77      0.75      0.76       304\n",
      "          37       0.50      0.68      0.58        28\n",
      "          39       0.21      0.24      0.22        34\n",
      "          40       0.52      0.63      0.57       108\n",
      "          41       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.50      8568\n",
      "   macro avg       0.38      0.44      0.40      8568\n",
      "weighted avg       0.51      0.50      0.51      8568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(xgb_2D.predict(X_test_2D), y_test_2D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae7d9e-6b83-4f76-98a7-0ab0b1ef5fc9",
   "metadata": {},
   "source": [
    "**Layer 3**: 3-Digit SSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eaf98e-7417-46c7-a31d-87eae9838a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_2D = pd.DataFrame(xgb_2D.predict_proba(X_train_2D))\n",
    "pred_proba_2D.columns = [f'pred_proba_2D_{col}' for col in pred_proba_2D.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d5209-6a89-40f2-8a2c-065fa892fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b6bae-b541-41e6-9a85-e18b77695523",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_3D = y_train.astype('str').str.slice(0, 3).map(encoding['SSOC_3D']['ssoc_idx']).tolist()\n",
    "y_test_3D = y_test.astype('str').str.slice(0, 3).map(encoding['SSOC_3D']['ssoc_idx']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609b3cf-ac88-4a7a-a6bb-f9482a0cf618",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3D = pd.concat([X_train, pred_proba_2D], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869e074-9a8a-4747-a3e4-2b7dcecd8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_2D = XGBClassifier(**xgb_params)\n",
    "xgb_2D.fit(X_train_2D, y_train_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b5694-5d32-4262-9886-e2ba4701d3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3facbff-37fb-4ef8-b9e4-3603cc0a44a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
