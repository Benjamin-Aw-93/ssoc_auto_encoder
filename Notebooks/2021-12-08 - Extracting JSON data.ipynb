{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc99a0f",
   "metadata": {},
   "source": [
    "## Extracting JSON data\n",
    "\n",
    "**Author:** Benjamin Aw  \n",
    "**Date:** 8 Dec 2021  \n",
    "**Context:** Creating new datasets in the form of CSV files for pre-training/training purposes  \n",
    "**Objective:** Compartmentilising the extracted files from JSON into CSV files split up by year-month  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7db20",
   "metadata": {},
   "source": [
    "#### A) Setting up\n",
    "\n",
    "Importing the libraries and setting up the path which contains the raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = \"../Data/Raw/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c5636",
   "metadata": {},
   "source": [
    "#### B) Writing out the necessary functions\n",
    "\n",
    "The function below aims to extact out infomation in the json file and compartmentalise it into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eca162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mcf_data(json):\n",
    "    \n",
    "    output = {}\n",
    "    transfer = ['uuid', 'title', 'description', 'minimumYearsExperience', 'numberOfVacancies']\n",
    "    # Extracting general information of the job posting\n",
    "    for key in transfer:\n",
    "        try:\n",
    "            output[key] = json[key]\n",
    "        except:\n",
    "            # If keys not found, treat file as failure to extract\n",
    "            return None, None\n",
    "\n",
    "    # Extract skills, skills are mainly captured in separate JSON objects \n",
    "    output['skills'] = ', '.join([entry['skill'] for entry in json['skills']])\n",
    "    \n",
    "    # Extract hiring company\n",
    "    company = ['name', 'description', 'ssicCode', 'employeeCount']\n",
    "    if json['metadata']['isPostedOnBehalf']:\n",
    "        company_col = 'hiringCompany'\n",
    "    else:\n",
    "        company_col = 'postedCompany'\n",
    "    for key in company:\n",
    "        try:\n",
    "            output['company_' + key] = json[company_col][key]\n",
    "        except TypeError:\n",
    "            output['company_' + key] = json[company_col]\n",
    "        \n",
    "    # Extract additional infomation such as the date of the post, number of views and applications etc\n",
    "    metadata = ['originalPostingDate', 'newPostingDate', 'expiryDate', 'totalNumberOfView', 'totalNumberJobApplication']\n",
    "    for key in metadata:\n",
    "        output[key] = json['metadata'][key]\n",
    "    \n",
    "    # Extract salary, if min and max is not available, return None which is captured in the except statement\n",
    "    salary = ['maximum', 'minimum']\n",
    "    for key in salary:\n",
    "        try:\n",
    "            output['salary_' + key] = json['salary'][key]\n",
    "        except TypeError:\n",
    "            output['salary_' + key] = json['salary']\n",
    "    \n",
    "    # Extract additional salary information\n",
    "    try:\n",
    "        output['salary_type_id'] = json['salary']['type']['id']\n",
    "        output['salary_type'] = json['salary']['type']['salaryType']\n",
    "    except TypeError:\n",
    "        output['salary_type_id'] = json['salary']\n",
    "        output['salary_type'] = json['salary']\n",
    "        \n",
    "    # Return the actual output, and the date of the post       \n",
    "    return output, output['originalPostingDate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb104b",
   "metadata": {},
   "source": [
    "The function below runs `extract_mcf_data` and splits up the data based on its year and month that it was posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53378b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_split(path):\n",
    "    \n",
    "    output = {}\n",
    "\n",
    "    for filename in os.listdir(path + \"mcf_raw\"):    \n",
    "        \n",
    "        print(f'Reading in {filename}')\n",
    "        f = open(path + \"/mcf_raw/\" + filename)\n",
    "        entry = json.load(f)\n",
    "        \n",
    "        extracted_result, date = extract_mcf_data(entry)\n",
    "\n",
    "        if extracted_result:\n",
    "            date_year_mth = date[0:7]\n",
    "            if date_year_mth in output: \n",
    "                output[date_year_mth].append(extracted_result)\n",
    "            else:\n",
    "                output[date_year_mth] = [extracted_result]\n",
    "        else:\n",
    "            print(f'{filename} has missing key values')\n",
    "            fi = open(path + \"json_to_remove.txt\", \"a\")\n",
    "            fi.write(f'{filename}\\n')\n",
    "            fi.close()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac0d6e",
   "metadata": {},
   "source": [
    "The function below takes the output from `extract_and_split` and turns them into csv files based on the year and the month of the job posting, which is captured as keys in `output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(path, output):\n",
    "    \n",
    "    for dates in output.keys():\n",
    "        pd.DataFrame(output[dates]).to_csv(path + \"raw_csv/raw_\" + dates + \".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf548565",
   "metadata": {},
   "source": [
    "#### C) Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7843b23",
   "metadata": {},
   "source": [
    "Running the code to get the extacted dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e38cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = extract_and_split(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f635e",
   "metadata": {},
   "source": [
    "Checking the difference in length between the input and the output. \n",
    "\n",
    "This will give us an idea of how much entries are actually dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_len = len(os.listdir(path + \"mcf_api_responses\"))\n",
    "bad_len = len(open(path + \"json_to_remove.txt\", \"r\").readlines())\n",
    "\n",
    "print(f'Total number of entries orginally: {before_len}')\n",
    "\n",
    "print(f'Number of bad entries: {bad_len}')\n",
    "\n",
    "print(f'Total number of entries after dropping: {before_len - bad_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bbfc4",
   "metadata": {},
   "source": [
    "Writing the outputs into individual csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(path, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50853ae4",
   "metadata": {},
   "source": [
    "#### E) Run only once\n",
    "\n",
    "Because all the faulty json files are saved into `json_to_remove.txt`, we need to remove them from our current datasets. Trying to remove them concurrently will result in a windows access error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6dba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path + \"json_to_remove.txt\", \"r\")\n",
    "\n",
    "for files in f:\n",
    "    file = files.strip()\n",
    "    print(f'{file} moved')\n",
    "    os.rename(f\"{path}mcf_raw/{file}\", f\"{path}json_to_remove/{file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
