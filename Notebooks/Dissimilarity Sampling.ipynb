{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for sampling based on dissimilar job titles\n",
    "Last updated: 17th September 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "import re\n",
    "import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from multiprocessing import  Pool\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and cleaning data\n",
    "\n",
    "Reading the csv files, filter only Job ID and Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcf_df = pd.read_csv(\"..\\Data\\Processed\\WGS_Dataset_JobInfo_precleaned.csv\")\n",
    "mcf_df = mcf_df[[\"Job_ID\", \"Title\"]].sample(frac=0.1, random_state=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up job titles based on eyeballing of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing everything within [...], (...), #sgunitiedjob, 3-4 digit number, dash and chinese characters\n",
    "\n",
    "cleaning_regex= ['\\[.*?\\]', '\\(.*?\\)', '#sgunitedjobs*', '^\\d{2,5}', '-', '#sgunitedtraineeships', '#sgups*', '#sguniteds*', '#sg', '#(\\w+)', '\\d{4,}']\n",
    "\n",
    "# Iteratively apply each regex\n",
    "for regex in cleaning_regex:\n",
    "    mcf_df['Title'] = mcf_df['Title'].map(lambda text: re.sub(regex, '', text).strip())\n",
    "\n",
    "# Remove non ACSII characters (0 to 122), chinese and specical characters\n",
    "mcf_df['Title'] = mcf_df['Title'].map(lambda text: re.sub(\"([^\\x00-\\x7F])+\",\" \",text))\n",
    "\n",
    "# Remove all other symbols \n",
    "mcf_df['Title'] = mcf_df['Title'].map(lambda text: re.sub(r'[^a-zA-Z0-9\\s]','', text))\n",
    "\n",
    "# Remove double spacings\n",
    "mcf_df['Title'] = mcf_df['Title'].map(lambda text: re.sub(\"\\s\\s+\" , \" \", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting to get initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setting random number\n",
    "random.seed(1)\n",
    "random_row = random.randint(0, mcf_df.shape[0])\n",
    "\n",
    "#selecting the first entry to be in the test set randomly\n",
    "mcf_df_test = mcf_df.iloc[[random_row]]\n",
    "\n",
    "#removing selected entry from exisitng data\n",
    "mcf_df_existing = mcf_df.drop([random_row])\n",
    "mcf_df_existing.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get text similarity between two string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the difference between two strings of text\n",
    "\n",
    "def distance_text(text1, text2):\n",
    "    text1 = nlp(text1)\n",
    "    text2 = nlp(text2)\n",
    "    return text1.similarity(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating to compare and split the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc191fe446142aa90d2d3a8a95fe877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall progress:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e50e22b978448189f4024ef939ae80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping progress:   0%|          | 0/23306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin\\Desktop\\my_enviro\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 done. Number of entries in test: 2, Number of entries remaining: 23305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514e4dd87a9a4f60baf4707e5dc136ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping progress:   0%|          | 0/23305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b294da892342a3b24a9b6b3f5aafa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping progress:   0%|          | 0/23305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Mapping progress\")\n",
    "\n",
    "for _ in trange(500, desc=\"Overall progress\"):\n",
    "    for title_ref in mcf_df_test[\"Title\"]:\n",
    "        if \"Distance\" not in mcf_df_existing.columns:\n",
    "            mcf_df_existing[\"Distance\"] = mcf_df_existing[\"Title\"].progress_map(lambda title: distance_text(title, title_ref))\n",
    "        else:\n",
    "            mcf_df_existing[\"Distance\"] = mcf_df_existing[\"Distance\"] + mcf_df_existing[\"Title\"].progress_map(lambda title: distance_text(title, title_ref))\n",
    "\n",
    "    mcf_df_existing[\"Distance\"] = mcf_df_existing[\"Distance\"]/len(mcf_df_test)\n",
    "\n",
    "    mcf_df_test = pd.concat([mcf_df_test, mcf_df_existing.sort_values('Distance').iloc[[0]][['Job_ID', 'Title']]])\n",
    "\n",
    "    mcf_df_existing = mcf_df_existing.sort_values('Distance').iloc[1:, :][['Job_ID', 'Title']]\n",
    "    \n",
    "    print(f'Round {_} done. Number of entries in test: {mcf_df_test.shape[0]}, Number of entries remaining: {mcf_df_existing.shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_enviro",
   "language": "python",
   "name": "my_enviro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
